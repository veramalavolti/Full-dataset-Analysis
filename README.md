# Machine learning Final Project
Studio del dataset student-por per analizzare i fattori che influenzano il voto finale (G3) e costruire modelli di regressione (Random Forest, SVR) ottimizzati con RandomizedSearchCV.

Questo progetto applica metodi di data science al **Student Performance Dataset (UCI)** per analizzare i fattori che influenzano il rendimento scolastico e costruire modelli predittivi accurati.

L‚Äôanalisi comprende:
- Exploratory Data Analysis (EDA)
- Preprocessing con Pipeline e ColumnTransformer
- Confronto di modelli supervisionati (Linear Regression, Random Forest, SVR)
- Tuning degli iperparametri con RandomizedSearchCV
- Interpretazione dei risultati tramite feature importance

## Il dataset e gli obiettivi
<img width="1002" height="564" alt="image" src="https://github.com/user-attachments/assets/1c8d3897-9b13-40a4-8f49-d1f4366b8330" />

- **Fonte:** UCI Machine Learning Repository  
- **File usato:** `student-por.csv` (corso di lingua portoghese)  
- **Dimensioni:** 649 studenti √ó 33 variabili  

### Tipologie di variabili
- **Famiglia/Sociale:** istruzione dei genitori, occupazione, dimensione familiare  
- **Personale/Comportamentale:** et√†, genere, attivit√† sociali, consumo di alcol  
- **Scolastiche:** tempo di studio, assenze, supporto educativo  
- **Performance:** G1, G2, G3 (voti ai diversi periodi)

Questo dataset integra aspetti sociali, comportamentali e scolastici, rendendolo ideale per analisi descrittive e predittive.

<img width="1002" height="564" alt="image" src="https://github.com/user-attachments/assets/aaa9eb3b-620e-40c9-80d5-9ffd1e941fc3" />

### Obiettivi del progetto
- Predire il **voto finale (G3)** tramite modelli di regressione.
- Confrontare le performance di diversi algoritmi.
- Ottimizzare gli iperparametri mediante **RandomizedSearchCV + Nested Cross-Validation**.
- Individuare i fattori che influenzano maggiormente il rendimento.
- Derivare insight utili per supportare studenti in contesti svantaggiati.

L‚Äôobiettivo √® unire rigore tecnico e utilit√† pedagogica.


## Struttura dettagliata del progetto

### 1. Setup dell‚Äôambiente e import delle librerie
Configuro l‚Äôambiente di lavoro importando le librerie necessarie per analisi e modellazione:
- `pandas`, `numpy` per manipolazione dati  
- `matplotlib`, `seaborn` per visualizzazioni  
- `scikit-learn` per preprocessing, modelli e validazione  

Imposto anche opzioni di stile e un seed per garantire riproducibilit√†.

---

### 2. Caricamento e ispezione iniziale del dataset
Carico il file `student-por.csv` e verifico:
- prime righe del dataset  
- struttura (shape, tipi di variabili, categorie)  
- presenza di valori mancanti  
- coerenza generale dei dati  

Questa fase introduce la struttura del dataset e permette di individuare eventuali criticit√† iniziali.

---

### 3. Analisi Esplorativa dei Dati (EDA)

<img width="1002" height="564" alt="image" src="https://github.com/user-attachments/assets/de712f76-0ddb-4432-9beb-75fa1794efd6" />

### Risultati principali dell‚ÄôEDA
- **Correlazioni forti:**  
  - G3 √® strettamente correlato con **G1 (0.80)** e **G2 (0.91)**.
- **Fattori positivi:** tempo di studio, istruzione dei genitori.  
- **Fattori negativi:** fallimenti passati, consumo di alcol.  
- **Distribuzione di G3:** centrata attorno all‚Äô11‚Äì12, ma con ampia variabilit√† (0‚Äì19).


---

# üü£ **Slide 5 ‚Äî Metodologia**
<img width="1405" height="786" alt="image" src="https://github.com/user-attachments/assets/be9a11bd-0d59-4b43-a15d-6161a4a73090" />

### üß™ Workflow

1. **EDA**
   - Analisi delle distribuzioni, pattern e correlazioni.

2. **Preprocessing**
   - Numeriche ‚Üí imputazione + standard scaling  
   - Categoriali ‚Üí imputazione + One-Hot Encoding  
   - Implementato con `ColumnTransformer` + `Pipeline`.

3. **Scenari**
   - **A:** include G1 e G2 (scenario benchmark)  
   - **B:** esclude G1 e G2 (scenario realistico di inizio anno)

4. **Modelli**
   - Linear Regression  
   - Random Forest Regressor  
   - Support Vector Regressor

5. **Hyperparameter Tuning**
   - RandomizedSearchCV + Nested Cross-Validation

6. **Valutazione**
   - MAE, RMSE, R¬≤

7. **Interpretazione**
   - Permutation Importance per capire le variabili pi√π rilevanti

pipe = Pipeline([
    ("preprocess", preprocessor),
    ("model", RandomForestRegressor())
])



#### 3.3 Analisi di gruppi
Studio come cambia `G3` in base a:
- consumo settimanale di alcol (`Dalc`)  
- consumo nel weekend (`Walc`)  
- supporto scolastico (`schoolsup`)  
- assenze (`absences`)  
- tempo libero, salute e relazioni sociali  

Questa parte individua pattern utili per capire quali variabili possono essere predittive.

---

### 4. Preparazione dei dati (Preprocessing)

#### 4.1 Codifica variabili categoriche
Trasformo le variabili categoriche in variabili numeriche tramite One-Hot Encoding, per rendere i dati compatibili con i modelli.

#### 4.2 Scaling delle feature
Applico lo scaling (StandardScaler) nei modelli sensibili alla scala (es. SVR).  
I Random Forest non obbligano lo scaling, ma mantengo uniformit√† tra gli esperimenti.

#### 4.3 Suddivisione del dataset
Divido i dati in:
- **Training set (80%)**
- **Test set (20%)**

per valutare i modelli in maniera imparziale ed evitare leakage.

---

### 5. Impostazione dei due scenari di modellazione

#### Scenario A ‚Äî Senza G1 e G2
Prevedo `G3` utilizzando solo variabili socio-familiari, personali e scolastiche **senza i voti intermedi**.  
Simula un contesto realistico dove i voti precedenti non sono disponibili.

#### Scenario B ‚Äî Con G1 e G2
Aggiungo `G1` e `G2` alle feature.  
Serve per valutare quanto i voti intermedi migliorano la previsione del voto finale.

---

### 6. Modelli di Machine Learning

#### 6.1 Baseline
Creo una baseline che predice sempre la media del training set.  
Serve come riferimento minimo: ogni modello deve superarla per essere considerato utile.

---

#### 6.2 Random Forest Regressor
Modello non lineare basato su decision tree aggregati.  
Iperparametri ottimizzati:
- `n_estimators`  
- `max_depth`  
- `min_samples_split`  
- `min_samples_leaf`  
- `max_features`  

√à robusto, gestisce interazioni tra variabili e permette di stimare l‚Äôimportanza delle feature.

---

#### 6.3 Support Vector Regression (SVR)
Modello basato su margini ottimizzati e kernel non lineari.  
Iperparametri ottimizzati:
- `C`  
- `epsilon`  
- `kernel` (lineare/RBF)  
- `gamma`  

Risulta potente ma molto sensibile allo scaling e alla scelta dei parametri.

---

### 7. Ottimizzazione tramite RandomizedSearchCV
Utilizzo `RandomizedSearchCV` per ricercare iperparametri ottimali.

#### Perch√© Random Search?
- esplora parametri in modo casuale ‚Üí pi√π efficiente della grid search  
- permette di testare uno spazio di ricerca molto pi√π ampio  
- con meno tempo trova spesso soluzioni migliori  
- evita di esplorare solo combinazioni rigidamente predefinite  

Ogni modello viene validato tramite cross-validation per ridurre il rischio di overfitting.

---

### 8. Valutazione dei modelli

#### Metriche utilizzate
- **MAE** (errore medio in punti di voto)  
- **RMSE** (errore pesato, penalizza errori grandi)  
- **R¬≤** (variabilit√† spiegata dal modello)  

#### Analisi degli errori
- confronto tra predizioni e valori reali  
- analisi dei residui  
- identificazione degli studenti su cui il modello sbaglia di pi√π  

Serve per capire pattern nascosti e limiti dei modelli.
<img width="1440" height="807" alt="image" src="https://github.com/user-attachments/assets/604597d5-21e0-45cc-ab18-acb5abe56d0c" />

---

### 9. Conclusioni e spunti finali
<img width="1405" height="786" alt="image" src="https://github.com/user-attachments/assets/e7f34e67-8d1b-4a41-a4fc-b8a7f21519ea" />

### üìå Sintesi
Il **Random Forest** √® il modello pi√π stabile e affidabile.  
La rimozione di G1/G2 riduce sensibilmente la capacit√† predittiva, sottolineando che le previsioni di inizio anno devono basarsi su indicatori comportamentali, scolastici e familiari.

Il rendimento √® un fenomeno multidimensionale.


<img width="1440" height="807" alt="image" src="https://github.com/user-attachments/assets/e2a6b49d-de03-4aeb-b92d-108586daf03e" />

### ‚≠ê Variabili pi√π importanti (Permutation Importance)
- ‚ùå **Failures:** forte impatto negativo
- üö´ **Assenze:** l‚Äôalta frequenza di assenze riduce i risultati
- ‚è≥ **Studytime:** pi√π ore di studio = performance maggiore
- üéì **Medu/Fedu:** maggiore istruzione dei genitori ‚Üí voti pi√π alti
- üç∑ **Dalc/Walc:** il consumo di alcol penalizza significativamente

```python
from sklearn.inspection import permutation_importance
perm = permutation_importance(model, X_test, y_test)

```markdown
### üß† Interpretazione del Random Forest
- I fallimenti passati sono il predittore negativo pi√π forte.
- Il tempo di studio contribuisce positivamente, seppur con ritorni decrescenti.
- Consumo di alcol e assenze elevate compromettono i risultati.
- L‚Äôistruzione dei genitori conferma il peso del contesto socio-familiare.

Il rendimento scolastico emerge da un insieme di abitudini, risorse familiari e coinvolgimento scolastico.


<img width="1440" height="807" alt="image" src="https://github.com/user-attachments/assets/43bedcce-6853-4f7e-803c-1049f8a48b0b" />
### üõ†Ô∏è Azioni suggerite
1. Tutoraggio personalizzato per studenti con fallimenti precedenti  
2. Rafforzamento delle abitudini di studio efficaci  
3. Monitoraggio preventivo delle assenze  
4. Maggior coinvolgimento delle famiglie con basso livello di istruzione

Queste strategie trasformano gli insight del modello in interventi concreti.

### üèÅ Considerazioni finali
Il progetto mostra come i dati scolastici possano supportare l‚Äôidentificazione precoce di rischi educativi.  
Le variabili comportamentali, sociali e familiari emergono come fattori determinanti.

üëâ Il notebook completo √® disponibile nel repository.

I modelli non sostituiscono gli insegnanti: li supportano nel prendere decisioni basate su evidenze.



